<h2 id="music-sheet-transcriber">Music Sheet transcriber</h2>
<ul>
<li>paper: <a href="https://www.mdpi.com/2076-3417/8/4/606" class="uri">https://www.mdpi.com/2076-3417/8/4/606</a></li>
<li>loss : <a href="https://mediatum.ub.tum.de/doc/1292048/file.pdf" class="uri">https://mediatum.ub.tum.de/doc/1292048/file.pdf</a></li>
<li>from sheet to ABC</li>
<li>Uses CNN for feature encoding, then BLSTM and special loss CTC. Investigate!</li>
<li>Monophonic …</li>
<li>Works quite well, ~10% wrong with only 1 thing to fix. Gets more then notes right</li>
</ul>
<h2 id="music-transciption-by-deep-learning-paper">Music Transciption by Deep Learning paper</h2>
<ul>
<li>using basic models</li>
<li>Augmentation seems basic …</li>
<li>does not work very well :/</li>
<li>lossless: Use spectogramms …, use reverse series …, image augmentations …, crop bootstrapping</li>
<li>lossy: dont use?</li>
<li>Look at “An end-to-end neural network for polyphonic piano music transcription” ? <a href="https://arxiv.org/abs/1609.04243" class="uri">https://arxiv.org/abs/1609.04243</a></li>
<li>Look at “Convolutional recurrent neural networks for music classification” ? <a href="https://arxiv.org/abs/1508.01774" class="uri">https://arxiv.org/abs/1508.01774</a></li>
</ul>
<h2 id="musenet">Musenet</h2>
<h3 id="related-links">Related Links</h3>
<ul>
<li><a href="https://openai.com/blog/sparse-transformer/" class="uri">https://openai.com/blog/sparse-transformer/</a></li>
<li>Sparse transformer <a href="https://arxiv.org/abs/1904.10509" class="uri">https://arxiv.org/abs/1904.10509</a> ; Code: <a href="https://arxiv.org/abs/1904.10509" class="uri">https://arxiv.org/abs/1904.10509</a></li>
</ul>
